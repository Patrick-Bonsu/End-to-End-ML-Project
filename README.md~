# End-to-End-ML-Project
This project used the Titanic Datasets from Kaggle to build and deploy a machine learning projects using AWS ECR2


Implementation:

The project involves extensive data preprocessing using Pandas and NumPy to handle missing values, encode categorical features, and create meaningful derived features. 
Exploratory data analysis is conducted using Seaborn and Matplotlib to gain insights into the relationships between various features and survival outcomes.

Multiple machine learning models, including CatBoost and XGBoost, are trained and evaluated using Scikit-learn. 
Ensemble techniques are employed to harness the predictive power of diverse models, ensuring robust performance on unseen data.

Deployment:

The classification model is deployed using Flask, providing an intuitive web interface for users to interactively predict survival probabilities based on input features. 
This deployment showcases the practical application of machine learning models in real-world scenarios.

Achievements:

This project demonstrates proficiency in data preprocessing, exploratory data analysis, and the implementation of machine learning models for classification tasks. 
The utilization of ensemble methods highlights a comprehensive understanding of advanced machine learning techniques. 
The deployment of the model as a web application underscores the ability to translate machine learning solutions into user-friendly applications.



AWS deployment

# End to end Titanic-Project



# How to run?
### STEPS:

Clone the repository

```bash
https://github.com/Patrick-Bonsu/End-to-End-ML-Project
```
### STEP 01- Create a conda environment after opening the repository

```bash
conda create -n summary python=3.8 -y
```

```bash
conda activate summary
```


### STEP 02- install the requirements
```bash
pip install -r requirements.txt
```


```bash
# Finally run the following command
python application.py
```

Now,
```bash
open up you local host and port
```


```bash
Author: Pattrick Yeboah Bonsu
Data Scientist
Email: bonsuyeboahmurphy@gmail.com

```



# AWS-CICD-Deployment-with-Github-Actions

## 1. Login to AWS console.

## 2. Create IAM user for deployment

	#with specific access

	1. EC2 access : It is virtual machine

	2. ECR: Elastic Container registry to save your docker image in aws


	#Description: About the deployment

	1. Build docker image of the source code

	2. Push your docker image to ECR

	3. Launch Your EC2 

	4. Pull Your image from ECR in EC2

	5. Lauch your docker image in EC2

	#Policy:

	1. AmazonEC2ContainerRegistryFullAccess

	2. AmazonEC2FullAccess

	
## 3. Create ECR repo to store/save docker image
    - Save the URI: 333158097126.dkr.ecr.us-east-1.amazonaws.com/text-s

	
## 4. Create EC2 machine (Ubuntu) 

## 5. Open EC2 and Install docker in EC2 Machine:
	
	
	#optinal

	sudo apt-get update -y

	sudo apt-get upgrade
	
	#required

	curl -fsSL https://get.docker.com -o get-docker.sh

	sudo sh get-docker.sh

	sudo usermod -aG docker ubuntu

	newgrp docker
	
# 6. Configure EC2 as self-hosted runner:
    setting>actions>runner>new self hosted runner> choose os> then run command one by one


# 7. Setup github secrets:

    AWS_ACCESS_KEY_ID=

    AWS_SECRET_ACCESS_KEY=

    AWS_REGION = us-east-1

    AWS_ECR_LOGIN_URI = 

    ECR_REPOSITORY_NAME = testS
